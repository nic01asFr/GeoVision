"""
Moteur YOLO - Interface principale pour la d√©tection d'objets et l'entra√Ænement

Ce module contient la classe YOLOEngine qui g√®re:
- Le chargement et la mise en cache des mod√®les YOLO
- La d√©tection d'objets sur images individuelles et en batch
- L'entra√Ænement de mod√®les personnalis√©s via transfer learning
- L'optimisation GPU/CPU avec fallback automatique
- La gestion de la m√©moire pour les gros datasets
"""

import os
import sys
import gc
import psutil
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Callable
from datetime import datetime
from collections import OrderedDict

import numpy as np
import torch
import cv2
from PIL import Image

# Import conditionnel d'Ultralytics YOLO
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("Warning: Ultralytics YOLO not available. Please install with: pip install ultralytics")


class LRUCache:
    """
    Cache LRU simple pour les mod√®les YOLO
    """
    def __init__(self, maxsize: int = 3):
        self.maxsize = maxsize
        self.cache = OrderedDict()
    
    def get(self, key):
        if key in self.cache:
            # D√©place vers la fin (plus r√©cent)
            value = self.cache.pop(key)
            self.cache[key] = value
            return value
        return None
    
    def put(self, key, value):
        if key in self.cache:
            self.cache.pop(key)
        elif len(self.cache) >= self.maxsize:
            # Supprime le plus ancien
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
            # Force garbage collection pour lib√©rer la m√©moire GPU
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        self.cache[key] = value


class DeviceManager:
    """
    Gestionnaire intelligent des devices GPU/CPU
    """
    
    @staticmethod
    def detect_optimal_device():
        """
        D√©tecte le device optimal pour YOLO
        
        Returns:
            str: Device optimal ('cuda:0', 'mps', 'cpu')
        """
        # NVIDIA CUDA
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            # S√©lectionne le GPU avec le plus de m√©moire libre
            best_gpu = 0
            max_free_memory = 0
            
            for i in range(device_count):
                try:
                    free_memory = torch.cuda.mem_get_info(i)[0]
                    if free_memory > max_free_memory:
                        max_free_memory = free_memory
                        best_gpu = i
                except:
                    pass
                    
            return f'cuda:{best_gpu}'
        
        # Apple Metal Performance Shaders (Apple Silicon)
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return 'mps'
        
        # CPU comme fallback
        return 'cpu'
    
    @staticmethod
    def get_device_info(device: str) -> Dict:
        """
        Retourne les informations d√©taill√©es sur un device
        
        Args:
            device: Device string ('cuda:0', 'mps', 'cpu')
            
        Returns:
            dict: Informations sur le device
        """
        info = {'device': device, 'available': True}
        
        if device.startswith('cuda'):
            if torch.cuda.is_available():
                gpu_id = int(device.split(':')[1]) if ':' in device else 0
                info.update({
                    'name': torch.cuda.get_device_name(gpu_id),
                    'memory_total': torch.cuda.get_device_properties(gpu_id).total_memory,
                    'memory_free': torch.cuda.mem_get_info(gpu_id)[0],
                    'compute_capability': torch.cuda.get_device_properties(gpu_id).major
                })
            else:
                info['available'] = False
                
        elif device == 'mps':
            info.update({
                'name': 'Apple Metal GPU',
                'memory_total': -1,  # Non accessible
                'memory_free': -1
            })
            
        elif device == 'cpu':
            info.update({
                'name': f'CPU ({torch.get_num_threads()} threads)',
                'memory_total': psutil.virtual_memory().total,
                'memory_free': psutil.virtual_memory().available,
                'cores': os.cpu_count()
            })
            
        return info


class YOLOEngine:
    """
    Moteur principal pour la d√©tection d'objets YOLO
    
    Cette classe fournit une interface haut niveau pour:
    - Charger et g√©rer des mod√®les YOLO
    - Effectuer des d√©tections sur images individuelles ou par batch
    - Entra√Æner des mod√®les personnalis√©s
    - Optimiser les performances selon le hardware disponible
    """
    
    def __init__(self, max_cached_models: int = 3):
        """
        Initialise le moteur YOLO
        
        Args:
            max_cached_models: Nombre maximum de mod√®les en cache
        """
        if not YOLO_AVAILABLE:
            raise ImportError("Ultralytics YOLO not available. Please install with: pip install ultralytics")
        
        # S√âCURIT√â: Configurer NumPy pour √©viter les conflits 2.x
        self._configure_numpy_compatibility()
        
        # S√âCURIT√â: Configurer Ultralytics pour √©viter l'acc√®s aux Documents
        self._configure_ultralytics_paths()
            
        # D√©tection du device optimal
        self.device = DeviceManager.detect_optimal_device()
        self.device_info = DeviceManager.get_device_info(self.device)
        
        # Cache des mod√®les charg√©s
        self.model_cache = LRUCache(maxsize=max_cached_models)
        self.current_model = None
        self.current_model_path = None
        
        # Configuration par d√©faut optimis√©e pour mod√®les custom
        self.default_confidence = 0.1  # ‚úÖ Beaucoup plus permissif pour mod√®les custom
        self.default_iou_threshold = 0.45
        self.batch_size = self._calculate_optimal_batch_size()
        
        print(f"YOLOEngine initialized with device: {self.device}")
        print(f"Device info: {self.device_info}")
        
        # V√©rification des mod√®les int√©gr√©s
        self._verify_integrated_models()

    def _configure_numpy_compatibility(self):
        """Configure NumPy pour √©viter les conflits de version"""
        try:
            import warnings
            import os
            
            # D√©sactiver les warnings NumPy 2.x (correction: utiliser Warning au lieu de UserWarning)
            try:
                warnings.filterwarnings("ignore", category=Warning, module="numpy")
                warnings.filterwarnings("ignore", message=".*NumPy.*")
                warnings.filterwarnings("ignore", category=Warning, message=".*category.*")
            except Exception as warn_error:
                print(f"‚ö†Ô∏è Erreur configuration warnings: {warn_error}")
            
            # Variables d'environnement pour forcer compatibilit√©
            os.environ['NUMPY_EXPERIMENTAL_DTYPE_API'] = '0'
            os.environ['NPY_DISABLE_OPTIMIZATION'] = '1'
            
            print("‚úÖ Configuration NumPy 2.x pour compatibilit√©")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur configuration NumPy: {e}")

    def _configure_ultralytics_paths(self):
        """Configure les chemins Ultralytics pour √©viter l'acc√®s aux Documents"""
        try:
            # S√âCURIT√â: Utiliser r√©pertoire du plugin au lieu de cwd()
            plugin_dir = Path(__file__).parent.parent
            secure_dir = plugin_dir.parent / 'qgis_yolo_detector_data'
            models_dir = secure_dir / 'models' / 'ultralytics'
            datasets_dir = secure_dir / 'datasets'
            runs_dir = secure_dir / 'runs'
            config_dir = secure_dir / 'config'
            
            # Cr√©er les r√©pertoires
            models_dir.mkdir(parents=True, exist_ok=True)
            datasets_dir.mkdir(parents=True, exist_ok=True)
            runs_dir.mkdir(parents=True, exist_ok=True)
            config_dir.mkdir(parents=True, exist_ok=True)
            
            # Configuration des variables d'environnement Ultralytics
            os.environ['YOLO_CONFIG_DIR'] = str(config_dir)
            os.environ['ULTRALYTICS_CONFIG_DIR'] = str(config_dir)
            os.environ['ULTRALYTICS_RUNS_DIR'] = str(runs_dir)
            
            # D√©sactiver les t√©l√©chargements automatiques depuis le web pour √©viter curl
            os.environ['YOLO_OFFLINE'] = '1'
            os.environ['ULTRALYTICS_OFFLINE'] = '1'
            os.environ['YOLO_NO_DOWNLOADS'] = '1'
            
            # S√âCURIT√â: D√©sactiver les t√©l√©chargements HuggingFace et autres
            os.environ['HF_OFFLINE'] = '1'
            os.environ['TRANSFORMERS_OFFLINE'] = '1'
            
            # D√©sactiver le logging externe qui peut causer des probl√®mes
            os.environ['WANDB_DISABLED'] = 'true'
            os.environ['COMET_OFFLINE'] = 'true'
            
            # Forcer le mode local pour √©viter les appels r√©seau
            os.environ['ULTRALYTICS_NO_HUB'] = '1'
            
            # Configuration du logging Ultralytics pour √©viter les erreurs de stream
            import logging
            # Cr√©er un handler qui fonctionne dans QGIS
            ultralytics_logger = logging.getLogger('ultralytics')
            ultralytics_logger.setLevel(logging.ERROR)
            
            # Supprimer les handlers par d√©faut qui peuvent causer des probl√®mes
            for handler in ultralytics_logger.handlers[:]:
                ultralytics_logger.removeHandler(handler)
            
            # Ajouter un handler simple qui √©crit dans la console QGIS
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setLevel(logging.ERROR)
            ultralytics_logger.addHandler(console_handler)
            
            print(f"‚úÖ Chemins Ultralytics configur√©s localement")
            print(f"üìÅ Mod√®les: {models_dir}")
            print(f"üìÅ Runs: {runs_dir}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur configuration Ultralytics: {e}")

    def _verify_integrated_models(self):
        """V√©rifie la pr√©sence et l'int√©grit√© des mod√®les int√©gr√©s"""
        plugin_dir = Path(__file__).parent.parent
        models_dir = plugin_dir / 'models' / 'pretrained'
        
        expected_models = {
            'yolo11n.pt': {'min_size': 5000000, 'max_size': 6000000},    # ~5.4 MB
            'yolo11s.pt': {'min_size': 18000000, 'max_size': 20000000},  # ~19 MB
            'yolo11m.pt': {'min_size': 38000000, 'max_size': 41000000}   # ~39 MB
        }
        
        available_models = []
        for model_name, constraints in expected_models.items():
            model_path = models_dir / model_name
            if model_path.exists():
                size = model_path.stat().st_size
                if constraints['min_size'] <= size <= constraints['max_size']:
                    available_models.append(model_name)
                    print(f"‚úÖ Mod√®le int√©gr√© OK: {model_name} ({size/1024/1024:.1f} MB)")
                else:
                    print(f"‚ö†Ô∏è Mod√®le corrompu: {model_name} (taille: {size/1024/1024:.1f} MB)")
            else:
                print(f"‚ùå Mod√®le manquant: {model_name}")
        
        if available_models:
            print(f"üéØ {len(available_models)}/3 mod√®les YOLO int√©gr√©s disponibles")
            # S√©lection automatique du meilleur mod√®le selon les performances
            self.recommended_model = self._select_optimal_model(available_models)
            print(f"üí° Mod√®le recommand√© pour votre syst√®me: {self.recommended_model}")
        else:
            print(f"‚ö†Ô∏è Aucun mod√®le int√©gr√© disponible - mode d√©grad√©")
            self.recommended_model = None

    def _select_optimal_model(self, available_models: list) -> str:
        """S√©lectionne le mod√®le optimal selon les capacit√©s du syst√®me"""
        # S√©lection intelligente bas√©e sur les performances du syst√®me
        if self.device.startswith('cuda'):
            # GPU disponible - peut utiliser des mod√®les plus lourds
            if 'yolo11m.pt' in available_models:
                return 'yolo11m.pt'  # Maximum performance
            elif 'yolo11s.pt' in available_models:
                return 'yolo11s.pt'  # Bon compromis
        
        # CPU ou GPU limit√© - privil√©gier la vitesse
        if 'yolo11s.pt' in available_models:
            return 'yolo11s.pt'  # √âquilibr√© par d√©faut
        elif 'yolo11n.pt' in available_models:
            return 'yolo11n.pt'  # L√©ger
        elif 'yolo11m.pt' in available_models:
            return 'yolo11m.pt'  # Pr√©cis mais plus lent
        
        return available_models[0] if available_models else None

    def _load_base_model_safely(self, base_model: str):
        """Charge un mod√®le de base en √©vitant les t√©l√©chargements non autoris√©s"""
        try:
            # Priorit√© 1: Mod√®les int√©gr√©s dans l'extension
            plugin_dir = Path(__file__).parent.parent
            integrated_model_path = plugin_dir / 'models' / 'pretrained' / base_model
            
            if integrated_model_path.exists():
                print(f"üéØ Utilisation du mod√®le int√©gr√©: {integrated_model_path}")
                return YOLO(str(integrated_model_path))
            
            # Priorit√© 2: Mod√®les dans le r√©pertoire de donn√©es utilisateur
            secure_dir = plugin_dir.parent / 'qgis_yolo_detector_data'
            local_model_path = secure_dir / 'models' / 'pretrained' / base_model
            
            if local_model_path.exists():
                print(f"üìÅ Utilisation du mod√®le local utilisateur: {local_model_path}")
                return YOLO(str(local_model_path))
            
            # Cr√©er un mod√®le basique si le mod√®le standard n'est pas disponible
            print(f"‚ö†Ô∏è Mod√®le {base_model} non trouv√© localement")
            print(f"üí° Cr√©ation d'un mod√®le basique pour l'entra√Ænement...")
            
            # Essayer de charger un mod√®le sans t√©l√©chargement
            import tempfile
            
            # Utiliser notre configuration locale
            local_config_path = plugin_dir / 'models' / 'yolov8n_local.yaml'
            
            if local_config_path.exists():
                print(f"üîß Utilisation de la configuration locale: {local_config_path}")
                model = YOLO(str(local_config_path))
            else:
                print(f"‚ö†Ô∏è Configuration locale non trouv√©e")
                print(f"üõ†Ô∏è Cr√©ation d'un mod√®le minimal depuis scratch...")
                
                # Solution de contournement : cr√©er un fichier de mod√®le vide local
                print(f"üõ†Ô∏è Cr√©ation d'un mod√®le vide local pour contourner les t√©l√©chargements...")
                
                local_models_dir = secure_dir / 'models' / 'pretrained'
                local_models_dir.mkdir(parents=True, exist_ok=True)
                
                # Utiliser notre configuration YAML locale √† la place
                yaml_config_path = plugin_dir / 'models' / 'yolov8n_local.yaml'
                try:
                    if yaml_config_path.exists():
                        print(f"üîß Utilisation de la configuration YAML locale: {yaml_config_path}")
                        model = YOLO(str(yaml_config_path))
                        return model
                    else:
                        raise FileNotFoundError("Configuration YAML locale non trouv√©e")
                except Exception as e_yaml:
                    print(f"‚ùå Erreur avec YAML local: {e_yaml}")
                    # Dernier recours : message d'erreur informatif
                    raise Exception(
                        f"‚ùå Impossible de cr√©er un mod√®le YOLO sans t√©l√©chargement.\n"
                        f"Solutions possibles:\n"
                        f"1. T√©l√©chargez manuellement yolo11n.pt depuis https://github.com/ultralytics/assets/releases/\n"
                        f"2. Placez-le dans: {local_models_dir}\n"
                        f"3. Ou autorisez temporairement les t√©l√©chargements"
                    )
            
            return model
            
        except Exception as e:
            print(f"‚ùå Erreur chargement mod√®le de base: {e}")
            raise Exception(f"Impossible de charger le mod√®le de base {base_model}: {e}")

    def _calculate_optimal_batch_size(self) -> int:
        """
        Calcule la taille de batch optimale selon le hardware disponible
        
        Returns:
            int: Taille de batch recommand√©e
        """
        if self.device.startswith('cuda'):
            # Estimation bas√©e sur la m√©moire GPU
            try:
                free_memory_gb = torch.cuda.mem_get_info()[0] / (1024**3)
                if free_memory_gb > 8:
                    return 32
                elif free_memory_gb > 4:
                    return 16
                elif free_memory_gb > 2:
                    return 8
                else:
                    return 4
            except:
                return 8
        else:
            # CPU ou MPS - batch size plus conservateur
            return 4

    def get_current_layer_pixel_size(self, layer):
        """Calcule la r√©solution actuelle de la couche"""
        try:
            extent = layer.extent()
            provider = layer.dataProvider()
            
            if hasattr(provider, 'xSize') and hasattr(provider, 'ySize'):
                # R√©solution = √©tendue / nombre de pixels
                pixel_size_x = (extent.xMaximum() - extent.xMinimum()) / provider.xSize()
                pixel_size_y = (extent.yMaximum() - extent.yMinimum()) / provider.ySize()
                return {'x': pixel_size_x, 'y': pixel_size_y}
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur calcul r√©solution: {e}")
        
        return {'x': 1.0, 'y': 1.0}  # D√©faut
    
    def calculate_scale_compatibility(self, current_pixel_size: float, 
                                    training_pixel_size: float) -> float:
        """
        Calcule la compatibilit√© d'√©chelle entre r√©solution actuelle et d'entra√Ænement
        
        Returns:
            float: Score 0-1 (1 = parfaitement compatible)
        """
        if training_pixel_size <= 0:
            return 0.0
        
        scale_ratio = current_pixel_size / training_pixel_size
        
        # Courbe de compatibilit√© : optimal √† 1.0, d√©cro√Æt exponentiellement
        if scale_ratio <= 0:
            return 0.0
        elif scale_ratio <= 0.25 or scale_ratio >= 4.0:
            return 0.1  # Tr√®s incompatible
        elif scale_ratio <= 0.5 or scale_ratio >= 2.0:
            return 0.5  # Moyennement compatible
        else:
            # Fonction gaussienne centr√©e sur 1.0
            import math
            return math.exp(-0.5 * ((math.log(scale_ratio)) ** 2) / (0.3 ** 2))

    def load_model(self, model_path: str, force_reload: bool = False) -> bool:
        """
        Charge un mod√®le YOLO avec mise en cache
        
        Args:
            model_path: Chemin vers le mod√®le (.pt)
            force_reload: Force le rechargement m√™me si en cache
            
        Returns:
            bool: True si le chargement a r√©ussi
        """
        # V√©rification de l'existence du fichier
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")
        
        # Utilisation du cache si disponible
        if not force_reload and self.current_model_path == model_path:
            return True
            
        cached_model = self.model_cache.get(model_path)
        if cached_model and not force_reload:
            self.current_model = cached_model
            self.current_model_path = model_path
            return True
        
        try:
            # Chargement du mod√®le avec gestion NumPy 2.x
            print(f"Loading YOLO model: {model_path}")
            
            # Workaround pour NumPy 2.x (correction: utiliser Warning)
            import warnings
            with warnings.catch_warnings():
                try:
                    warnings.filterwarnings("ignore", category=Warning, module="numpy")
                    warnings.filterwarnings("ignore", message=".*NumPy.*")
                    warnings.filterwarnings("ignore", category=Warning, message=".*category.*")
                except Exception:
                    pass  # Ignorer les erreurs de configuration des warnings
                
                model = YOLO(model_path)
            
            # Configuration du device
            model.to(self.device)
            
            # Mise en cache
            self.model_cache.put(model_path, model)
            self.current_model = model
            self.current_model_path = model_path
            
            print(f"Model loaded successfully on {self.device}")
            return True
            
        except Exception as e:
            print(f"Error loading model {model_path}: {str(e)}")
            return False

    def detect_objects(self, image_array: np.ndarray, 
                      confidence_threshold: Optional[float] = None,
                      iou_threshold: Optional[float] = None,
                      target_classes: Optional[List[int]] = None) -> List[Dict]:
        """
        D√©tecte des objets sur une image
        
        Args:
            image_array: Image en format numpy array (H, W, C)
            confidence_threshold: Seuil de confiance (0.0-1.0)
            iou_threshold: Seuil IoU pour NMS
            target_classes: Liste des classes cibles (None = toutes)
            
        Returns:
            List[Dict]: Liste des d√©tections avec format:
                {
                    'bbox': [x1, y1, x2, y2],  # Coordonn√©es absolues
                    'bbox_normalized': [x, y, w, h],  # Format YOLO normalis√©
                    'confidence': float,
                    'class_id': int,
                    'class_name': str
                }
        """
        if self.current_model is None:
            raise ValueError("No model loaded. Please load a model first.")
        
        # Param√®tres par d√©faut
        conf_threshold = confidence_threshold or self.default_confidence
        iou_threshold = iou_threshold or self.default_iou_threshold
        
        print(f"üîç DEBUG YOLO_ENGINE: detect_objects appel√©")
        print(f"üîç DEBUG YOLO_ENGINE: conf_threshold={conf_threshold}, iou_threshold={iou_threshold}")
        print(f"üîç DEBUG YOLO_ENGINE: current_model={self.current_model_name}")
        print(f"üîç DEBUG YOLO_ENGINE: image_array shape={image_array.shape}, dtype={image_array.dtype}")
        
        try:
            # Workaround pour NumPy 2.x - supprimer warnings (correction: utiliser Warning)
            import warnings
            with warnings.catch_warnings():
                try:
                    warnings.filterwarnings("ignore", category=Warning, module="numpy")
                    warnings.filterwarnings("ignore", message=".*NumPy.*")
                    warnings.filterwarnings("ignore", category=Warning, message=".*category.*")
                except Exception:
                    pass  # Ignorer les erreurs de configuration des warnings
                
                # D√©tection avec YOLO
                print(f"üîç DEBUG YOLO_ENGINE: Appel model.predict...")
                results = self.current_model(
                    image_array,
                    conf=conf_threshold,
                    iou=iou_threshold,
                    verbose=False
                )
                print(f"üîç DEBUG YOLO_ENGINE: R√©sultats re√ßus: {len(results) if results else 0} r√©sultat(s)")
            
            # Traitement des r√©sultats
            detections = []
            if results and len(results) > 0:
                result = results[0]  # Premier r√©sultat
                print(f"üîç DEBUG YOLO_ENGINE: result.boxes pr√©sent: {hasattr(result, 'boxes')}")
                
                if hasattr(result, 'boxes') and result.boxes is not None:
                    boxes = result.boxes
                    print(f"üîç DEBUG YOLO_ENGINE: Nombre de boxes: {len(boxes)}")
                    
                    for i in range(len(boxes)):
                        # Coordonn√©es de la bounding box
                        bbox_xyxy = boxes.xyxy[i].cpu().numpy()
                        confidence = float(boxes.conf[i].cpu().numpy())
                        class_id = int(boxes.cls[i].cpu().numpy())
                        
                        # Filtrage par classe si sp√©cifi√©
                        if target_classes and class_id not in target_classes:
                            continue
                        
                        # Conversion en format YOLO normalis√©
                        h, w = image_array.shape[:2]
                        x1, y1, x2, y2 = bbox_xyxy
                        
                        # Format YOLO: centre_x, centre_y, largeur, hauteur (normalis√©s)
                        bbox_normalized = [
                            ((x1 + x2) / 2) / w,  # centre_x
                            ((y1 + y2) / 2) / h,  # centre_y
                            (x2 - x1) / w,        # largeur
                            (y2 - y1) / h         # hauteur
                        ]
                        
                        # Nom de la classe
                        class_name = self.current_model.names.get(class_id, f"class_{class_id}")
                        
                        detection = {
                            'bbox': [float(x1), float(y1), float(x2), float(y2)],
                            'bbox_normalized': bbox_normalized,
                            'confidence': confidence,
                            'class_id': class_id,
                            'class_name': class_name,
                            'image_shape': (h, w)
                        }
                        
                        detections.append(detection)
            
            print(f"üîç DEBUG YOLO_ENGINE: Retour {len(detections)} d√©tections finales")
            return detections
            
        except Exception as e:
            print(f"Error during detection: {str(e)}")
            return []

    def batch_detect(self, image_arrays: List[np.ndarray],
                    confidence_threshold: Optional[float] = None,
                    iou_threshold: Optional[float] = None,
                    progress_callback: Optional[Callable] = None) -> List[List[Dict]]:
        """
        D√©tection par batch sur plusieurs images
        
        Args:
            image_arrays: Liste d'images numpy
            confidence_threshold: Seuil de confiance
            iou_threshold: Seuil IoU
            progress_callback: Callback de progression (progress: float 0-1)
            
        Returns:
            List[List[Dict]]: D√©tections pour chaque image
        """
        if not image_arrays:
            return []
            
        results = []
        total_images = len(image_arrays)
        
        # Traitement par batch selon la capacit√© du device
        for i in range(0, total_images, self.batch_size):
            batch = image_arrays[i:i + self.batch_size]
            batch_results = []
            
            for j, image in enumerate(batch):
                detections = self.detect_objects(
                    image, 
                    confidence_threshold=confidence_threshold,
                    iou_threshold=iou_threshold
                )
                batch_results.append(detections)
                
                # Callback de progression
                if progress_callback:
                    progress = (i + j + 1) / total_images
                    progress_callback(progress)
            
            results.extend(batch_results)
            
            # Nettoyage m√©moire entre les batches
            if self.device.startswith('cuda'):
                torch.cuda.empty_cache()
            gc.collect()
        
        return results

    def train_custom_model(self, dataset_config_path: str,
                          base_model: str = 'yolov8n.pt',
                          epochs: int = 100,  # ‚úÖ Plus d'√©poques pour petit dataset
                          batch_size: Optional[int] = None,
                          learning_rate: float = 0.01,  # ‚úÖ LR plus √©lev√© pour transfer learning
                          patience: int = 25,  # ‚úÖ Plus de patience
                          progress_callback: Optional[Callable] = None) -> Dict:
        """
        Entra√Æne un mod√®le personnalis√© via transfer learning
        
        Args:
            dataset_config_path: Chemin vers le fichier dataset.yaml
            base_model: Mod√®le de base pour transfer learning
            epochs: Nombre d'√©poques d'entra√Ænement
            batch_size: Taille de batch (None = auto)
            learning_rate: Taux d'apprentissage
            patience: Patience pour early stopping
            progress_callback: Callback de progression
            
        Returns:
            Dict: R√©sultats d'entra√Ænement
        """
        if not os.path.exists(dataset_config_path):
            raise FileNotFoundError(f"Dataset config not found: {dataset_config_path}")
        
        try:
            # Gestion s√©curis√©e des mod√®les de base
            model = self._load_base_model_safely(base_model)
            
            # Configuration de l'entra√Ænement
            train_batch_size = batch_size or self.batch_size
            
            # Callback personnalis√© pour le suivi de progression
            def on_epoch_end(trainer):
                if progress_callback:
                    epoch = trainer.epoch
                    total_epochs = trainer.args.epochs
                    progress = (epoch + 1) / total_epochs
                    progress_callback(progress, {
                        'epoch': epoch + 1,
                        'total_epochs': total_epochs,
                        'loss': float(trainer.loss) if hasattr(trainer, 'loss') else 0.0
                    })
            
            # Configuration du r√©pertoire de sortie pour √©viter l'erreur "runs"
            plugin_dir = Path(__file__).parent.parent
            secure_dir = plugin_dir.parent / 'qgis_yolo_detector_data'
            runs_dir = secure_dir / 'runs'
            runs_dir.mkdir(parents=True, exist_ok=True)
            
            # Configuration des variables d'environnement pour Ultralytics
            os.environ['ULTRALYTICS_RUNS_DIR'] = str(runs_dir)
            
            # D√©sactiver les logs verbeux d'Ultralytics pour √©viter les erreurs de stream
            import logging
            ultralytics_logger = logging.getLogger('ultralytics')
            ultralytics_logger.setLevel(logging.ERROR)
            
            # Entra√Ænement
            print(f"Starting training on {self.device}")
            results = model.train(
                data=dataset_config_path,
                epochs=epochs,
                batch=train_batch_size,
                lr0=learning_rate,
                patience=patience,
                device=self.device,
                save=True,
                save_period=10,  # Sauvegarde interm√©diaire
                val=True,
                plots=False,  # D√©sactiver les plots pour √©viter les erreurs
                verbose=False,  # R√©duire la verbosit√©
                exist_ok=True,  # √âcrase les r√©sultats pr√©c√©dents
                project=str(runs_dir),  # R√©pertoire projet explicite
                name='yolo_training'  # Nom du run
            )
            
            # R√©cup√©ration des chemins de sortie
            best_model_path = results.save_dir / 'weights' / 'best.pt'
            last_model_path = results.save_dir / 'weights' / 'last.pt'
            
            training_results = {
                'success': True,
                'best_model_path': str(best_model_path),
                'last_model_path': str(last_model_path),
                'save_dir': str(results.save_dir),
                'final_metrics': results.results_dict if hasattr(results, 'results_dict') else {},
                'training_time': getattr(results, 'training_time', 0),
                'device_used': self.device
            }
            
            print(f"Training completed successfully!")
            print(f"Best model saved to: {best_model_path}")
            
            return training_results
            
        except Exception as e:
            print(f"Error during training: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'device_used': self.device
            }

    def get_model_info(self) -> Dict:
        """
        Retourne les informations sur le mod√®le actuellement charg√©
        
        Returns:
            Dict: Informations sur le mod√®le
        """
        if self.current_model is None:
            return {'loaded': False}
        
        try:
            return {
                'loaded': True,
                'model_path': self.current_model_path,
                'classes': list(self.current_model.names.values()),
                'num_classes': len(self.current_model.names),
                'device': self.device,
                'model_type': 'YOLO'
            }
        except:
            return {'loaded': False, 'error': 'Could not retrieve model info'}

    def cleanup(self):
        """
        Nettoie les ressources (mod√®les, cache GPU)
        """
        self.model_cache.cache.clear()
        self.current_model = None
        self.current_model_path = None
        
        # Nettoyage GPU
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        gc.collect()
        print("YOLOEngine cleaned up")


# TODO pour Claude Code:
# 1. Tester le chargement de mod√®les YOLO pr√©-entra√Æn√©s
# 2. Impl√©menter des tests unitaires pour les d√©tections
# 3. Optimiser la gestion m√©moire pour les gros datasets
# 4. Ajouter support pour d'autres formats d'images
# 5. Impl√©menter le logging d√©taill√© pour debugging
# 6. Ajouter la validation des param√®tres d'entr√©e
# 7. G√©rer les cas d'erreur de mani√®re plus robuste
