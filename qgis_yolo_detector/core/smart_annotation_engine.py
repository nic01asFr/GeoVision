"""
Smart Annotation Engine - Pipeline YOLO‚ÜíSAM pour annotation assist√©e par IA

Ce module impl√©mente un pipeline intelligent qui :
- Utilise YOLO pour la d√©tection pr√©alable d'objets candidats
- Applique SAM (Segment Anything Model) pour le raffinement des contours
- Optimise les performances pour CPU normal (4-8 cores, 8-16GB RAM)
- Fournit des m√©tadonn√©es enrichies pour am√©liorer la qualit√© du training YOLO

Architecture performance-first :
- Lazy loading des mod√®les SAM (chargement uniquement si n√©cessaire)
- Profile performance CPU automatique avec fallback intelligent
- Cache LRU partag√© avec YOLOEngine existant
- Seuils adaptatifs selon les capacit√©s mat√©rielles
"""

import os
import gc
import time
import math
import threading
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Callable, Any
from dataclasses import dataclass
from datetime import datetime

# Imports conditionnels pour compatibilit√© QGIS
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

try:
    import numpy as np
    NUMPY_AVAILABLE = True
    
    # Protection sp√©cifique contre l'incompatibilit√© NumPy 1.x/2.x
    if hasattr(np, '__version__') and np.__version__.startswith('2.'):
        # NumPy 2.x d√©tect√© - protection suppl√©mentaire
        import warnings
        warnings.filterwarnings('ignore', category=RuntimeWarning, module='numpy')
        # Force l'utilisation de la compatibilit√© NumPy 1.x
        os.environ['NPY_DISABLE_OPTIMIZATION'] = '1'
        print(f"üîß NumPy 2.x d√©tect√© ({np.__version__}) - compatibilit√© 1.x activ√©e")
    
except ImportError as e:
    print(f"‚ö†Ô∏è NumPy non disponible: {e}")
    NUMPY_AVAILABLE = False
except Exception as e:
    print(f"‚ö†Ô∏è Erreur NumPy (compatibilit√© 1.x/2.x): {e}")
    # Fallback gracieux - continuer sans NumPy
    try:
        import numpy as np
        NUMPY_AVAILABLE = True
        print("‚úÖ NumPy charg√© en mode fallback")
    except:
        NUMPY_AVAILABLE = False
        print("‚ùå NumPy d√©finitivement indisponible")
    
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    
try:
    # Pr√©-configuration pour √©viter les conflits NumPy 1.x/2.x avec OpenCV
    import warnings
    with warnings.catch_warnings():
        warnings.filterwarnings('ignore', message='.*compiled using NumPy 1.x.*')
        import cv2
    CV2_AVAILABLE = True
    print(f"‚úÖ OpenCV charg√© avec protection NumPy ({cv2.__version__})")
except ImportError as e:
    print(f"‚ö†Ô∏è OpenCV non disponible: {e}")
    CV2_AVAILABLE = False
except Exception as e:
    print(f"‚ö†Ô∏è Erreur OpenCV (probablement NumPy 1.x/2.x): {e}")
    # Tentative de chargement en mode d√©grad√©
    try:
        import cv2
        CV2_AVAILABLE = True
        print("‚úÖ OpenCV charg√© en mode fallback")
    except:
        CV2_AVAILABLE = False
        print("‚ùå OpenCV d√©finitivement indisponible")
    
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

# Import conditionnel FastSAM (plus l√©ger que SAM standard)
try:
    from ultralytics import FastSAM
    FASTSAM_AVAILABLE = True
except ImportError:
    FASTSAM_AVAILABLE = False

# Import conditionnel MobileSAM (alternative ultra-l√©g√®re)
try:
    from mobile_sam import sam_model_registry, SamPredictor
    MOBILESAM_AVAILABLE = True
except ImportError:
    MOBILESAM_AVAILABLE = False


@dataclass
class SmartDetectionResult:
    """R√©sultat d'une d√©tection intelligente YOLO‚ÜíSAM"""
    bbox: List[float]  # [x1, y1, x2, y2] coordonn√©es optimis√©es
    bbox_original: List[float]  # Bbox YOLO originale
    confidence_yolo: float  # Confiance YOLO (0-1)
    confidence_sam: Optional[float]  # Confiance SAM si raffinement appliqu√©
    class_name: str
    class_id: int
    mask_available: bool  # True si masque SAM g√©n√©r√©
    mask_quality_score: Optional[float]  # Score qualit√© masque SAM
    refinement_applied: bool  # True si SAM a √©t√© utilis√©
    processing_time: float  # Temps total traitement (ms)
    improvement_ratio: Optional[float]  # Ratio am√©lioration bbox (SAM vs YOLO)
    
    # NOUVEAUX ATTRIBUTS POLYGONES SAM
    polygon_points: Optional[List[List[float]]] = None  # Points polygone [[x,y], [x,y], ...]
    polygon_available: bool = False  # True si polygone SAM disponible


@dataclass 
class CPUPerformanceProfile:
    """Profile de performance CPU pour optimisation automatique"""
    level: str  # 'low', 'medium', 'high'
    cpu_cores: int
    ram_gb: float
    recommended_yolo_size: str  # 'nano', 'small', 'medium'
    enable_sam: bool
    sam_model_type: str  # 'FastSAM', 'MobileSAM', 'none'
    max_concurrent_detections: int
    confidence_threshold_yolo: float
    confidence_threshold_sam: float


class CPUProfiler:
    """Profileur automatique des capacit√©s CPU pour optimisation"""
    
    @staticmethod
    def get_performance_profile() -> CPUPerformanceProfile:
        """
        Analyse les capacit√©s CPU/RAM et retourne un profile optimis√©
        
        Returns:
            CPUPerformanceProfile: Configuration optimale selon le mat√©riel
        """
        cpu_cores = os.cpu_count() or 4
        
        # RAM avec fallback si psutil non disponible
        if PSUTIL_AVAILABLE:
            ram_gb = psutil.virtual_memory().total / (1024**3)
        else:
            # Fallback conservateur si psutil non disponible
            ram_gb = 8.0  # Assume 8GB par d√©faut
        
        # CPU High-end (>=8 cores, >=16GB RAM)
        if cpu_cores >= 8 and ram_gb >= 16:
            return CPUPerformanceProfile(
                level='high',
                cpu_cores=cpu_cores,
                ram_gb=ram_gb,
                recommended_yolo_size='small',  # YOLOv8s pour √©quilibre perf/pr√©cision
                enable_sam=True,
                sam_model_type='FastSAM',
                max_concurrent_detections=4,
                confidence_threshold_yolo=0.15,
                confidence_threshold_sam=0.6
            )
        
        # CPU Medium (4-7 cores, 8-15GB RAM)
        elif cpu_cores >= 4 and ram_gb >= 8:
            return CPUPerformanceProfile(
                level='medium',
                cpu_cores=cpu_cores,
                ram_gb=ram_gb,
                recommended_yolo_size='nano',  # YOLOv8n tr√®s rapide
                enable_sam=True,
                sam_model_type='MobileSAM' if MOBILESAM_AVAILABLE else 'FastSAM',
                max_concurrent_detections=2,
                confidence_threshold_yolo=0.20,
                confidence_threshold_sam=0.7
            )
        
        # CPU Low-end (<4 cores ou <8GB RAM)
        else:
            return CPUPerformanceProfile(
                level='low',
                cpu_cores=cpu_cores,
                ram_gb=ram_gb,
                recommended_yolo_size='nano',
                enable_sam=False,  # D√©sactiv√© sur mat√©riel faible
                sam_model_type='none',
                max_concurrent_detections=1,
                confidence_threshold_yolo=0.25,
                confidence_threshold_sam=0.8
            )
    
    @staticmethod
    def benchmark_yolo_performance(yolo_engine, test_image_size=(640, 640)) -> float:
        """
        Benchmark rapide performance YOLO sur CPU
        
        Args:
            yolo_engine: Instance YOLOEngine
            test_image_size: Taille image test
            
        Returns:
            float: Temps moyen d√©tection (ms)
        """
        if not yolo_engine or not yolo_engine.current_model:
            return 1000.0  # Fallback conservateur
        
        # Image test synth√©tique
        test_image = np.random.randint(0, 255, (*test_image_size, 3), dtype=np.uint8)
        
        # 3 tests pour moyenne
        times = []
        for _ in range(3):
            start = time.time()
            try:
                yolo_engine.detect_objects(test_image, confidence_threshold=0.5)
                times.append((time.time() - start) * 1000)
            except:
                times.append(1000.0)  # Fallback en cas d'erreur
        
        return sum(times) / len(times)


class SmartAnnotationEngine:
    """
    Moteur principal d'annotation intelligente YOLO‚ÜíSAM
    
    Workflow optimis√© :
    1. R√©ception rectangle utilisateur (comme annotation manuelle)
    2. Extraction patch raster de la zone d'int√©r√™t
    3. D√©tection YOLO rapide pour identifier objets candidats
    4. S√©lection du meilleur candidat selon crit√®res g√©om√©triques/confiance
    5. Raffinement SAM optionnel si confiance YOLO insuffisante
    6. Retour bbox optimis√©e avec m√©tadonn√©es enrichies
    """
    
    def __init__(self, yolo_engine=None, annotation_manager=None):
        """
        Initialise le moteur d'annotation intelligente
        
        Args:
            yolo_engine: Instance YOLOEngine existante (r√©utilis√©e)
            annotation_manager: Gestionnaire annotations pour persistance
        """
        self.yolo_engine = yolo_engine
        self.annotation_manager = annotation_manager
        
        # V√©rification des d√©pendances critiques
        self.dependencies_available = self._check_dependencies()
        
        # Mod√®les SAM (lazy loading)
        self.sam_model = None
        self.sam_predictor = None
        self.sam_type = None
        
        # Configuration performance
        self.cpu_profile = CPUProfiler.get_performance_profile()
        self.enabled = True
        self.debug_mode = False
        
        # Configuration contours pr√©cis (polygones SAM)
        self.enable_precise_contours = True  # Activ√© par d√©faut
        
        # Statistiques et cache
        self.detection_stats = {
            'total_detections': 0,
            'sam_refinements': 0,
            'auto_accepted': 0,
            'user_validated': 0,
            'avg_processing_time': 0.0
        }
        
        # Thread pool pour traitement asynchrone
        self._processing_lock = threading.Lock()
        
        # S√âCURIT√â: Protection sp√©cifique Windows contre les appels syst√®me malform√©s
        self._configure_windows_security()
        
        # Chargement automatique d'un mod√®le par d√©faut pour l'auto-d√©tection
        # TEMPORAIREMENT D√âSACTIV√â pour √©viter les blocages QGIS
        # self._load_default_model()
        
        print(f"ü§ñ SmartAnnotationEngine initialis√©")
        print(f"üìä Profile CPU: {self.cpu_profile.level} ({self.cpu_profile.cpu_cores} cores, {self.cpu_profile.ram_gb:.1f}GB)")
        print(f"üéØ YOLO recommand√©: {self.cpu_profile.recommended_yolo_size}")
        print(f"üé® SAM: {'Activ√©' if self.cpu_profile.enable_sam else 'D√©sactiv√©'} ({self.cpu_profile.sam_model_type})")
        
        if not self.dependencies_available['all_available']:
            print(f"‚ö†Ô∏è D√©pendances manquantes: {', '.join(self.dependencies_available['missing'])}")
            print(f"üìù Mode d√©grad√© activ√© - fonctionnalit√©s limit√©es")
    
    def _check_dependencies(self) -> Dict[str, Any]:
        """V√©rifie la disponibilit√© des d√©pendances"""
        missing = []
        
        if not NUMPY_AVAILABLE:
            missing.append('numpy')
        if not TORCH_AVAILABLE:
            missing.append('torch')
        if not CV2_AVAILABLE:
            missing.append('opencv-python')
        if not PIL_AVAILABLE:
            missing.append('pillow')
        if not PSUTIL_AVAILABLE:
            missing.append('psutil')
        
        return {
            'all_available': len(missing) == 0,
            'missing': missing,
            'numpy': NUMPY_AVAILABLE,
            'torch': TORCH_AVAILABLE,
            'cv2': CV2_AVAILABLE,
            'pil': PIL_AVAILABLE,
            'psutil': PSUTIL_AVAILABLE
        }
    
    def _configure_windows_security(self):
        """Configuration de s√©curit√© sp√©cifique Windows pour √©viter les appels syst√®me malform√©s"""
        try:
            import platform
            if platform.system() == 'Windows':
                # D√©sactiver les outils de logging externes qui peuvent causer des probl√®mes
                os.environ['WANDB_DISABLED'] = 'true'
                os.environ['TENSORBOARD_DISABLED'] = 'true'
                os.environ['COMET_OFFLINE'] = 'true'
                os.environ['NEPTUNE_OFFLINE'] = 'true'
                
                # Forcer l'utilisation de chemins absolus pour √©viter les arguments malform√©s
                os.environ['PYTHONDONTWRITEBYTECODE'] = '1'
                
                # D√©sactiver les outils de profiling qui peuvent causer des erreurs
                os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
                
                print("üõ°Ô∏è Protection Windows activ√©e - appels syst√®me s√©curis√©s")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur configuration s√©curit√© Windows: {e}")
    
    def _load_default_model(self):
        """
        Charge un mod√®le YOLO g√©n√©rique optimis√© pour orthophotos
        
        Priorit√©: Mod√®les g√©n√©riques valid√©s pour imagerie g√©ospatiale
        plut√¥t que mod√®les sp√©cialis√©s non valid√©s
        """
        if not self.yolo_engine:
            print("‚ö†Ô∏è Aucun YOLOEngine disponible pour le SmartAnnotationEngine")
            return
        
        try:
            # D√©terminer le mod√®le optimal selon le profil CPU
            model_size = self.cpu_profile.recommended_yolo_size
            
            # Chemin vers les mod√®les pr√©-entra√Æn√©s
            import os
            from pathlib import Path
            plugin_dir = Path(__file__).parent.parent
            models_dir = plugin_dir / "models" / "pretrained"
            
            # Mapping taille -> fichier mod√®le (optimis√©s pour orthophotos)
            model_files = {
                'nano': 'yolo11n.pt',    # L√©ger, id√©al CPU standard
                'small': 'yolo11s.pt',   # √âquilibr√© performance/pr√©cision
                'medium': 'yolo11m.pt'   # Haute pr√©cision pour CPU puissants
            }
            
            model_file = model_files.get(model_size, 'yolo11n.pt')  # Fallback nano
            model_path = models_dir / model_file
            
            if model_path.exists():
                success = self.yolo_engine.load_model(str(model_path))
                if success:
                    print(f"‚úÖ Mod√®le g√©n√©rique orthophoto charg√©: {model_file}")
                    print(f"üåç Optimis√© pour: Imagerie a√©rienne, infrastructure urbaine, objets g√©ospatiaux")
                else:
                    print(f"‚ùå √âchec chargement mod√®le: {model_file}")
            else:
                print(f"‚ö†Ô∏è Mod√®le non trouv√©: {model_path}")
                print(f"üìã Mod√®les disponibles dans {models_dir}:")
                if models_dir.exists():
                    for model_file in models_dir.glob("*.pt"):
                        print(f"   - {model_file.name}")
                print(f"‚ùå Smart Mode d√©sactiv√© - aucun mod√®le pr√©-t√©l√©charg√© disponible")
                self.enabled = False
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors du chargement du mod√®le par d√©faut: {e}")
    
    def _lazy_load_sam_model(self) -> bool:
        """
        Charge le mod√®le SAM de mani√®re paresseuse (uniquement quand n√©cessaire)
        
        Returns:
            bool: True si mod√®le charg√© avec succ√®s
        """
        if self.sam_model is not None:
            return True  # D√©j√† charg√©
        
        if not self.cpu_profile.enable_sam:
            print("‚ö†Ô∏è SAM d√©sactiv√© selon le profile CPU")
            return False
        
        try:
            print(f"‚è≥ Chargement {self.cpu_profile.sam_model_type}...")
            start_time = time.time()
            
            # Recherche des mod√®les SAM pr√©-t√©l√©charg√©s dans le r√©pertoire plugin
            plugin_dir = Path(__file__).parent.parent
            sam_models_dir = plugin_dir / "models" / "sam"
            sam_models_dir.mkdir(parents=True, exist_ok=True)
            
            if self.cpu_profile.sam_model_type == 'FastSAM' and FASTSAM_AVAILABLE:
                # FastSAM via mod√®le local uniquement
                fastsam_path = sam_models_dir / 'FastSAM-s.pt'
                if fastsam_path.exists():
                    self.sam_model = FastSAM(str(fastsam_path))
                    self.sam_type = 'FastSAM'
                    print(f"‚úÖ FastSAM charg√© depuis: {fastsam_path}")
                else:
                    print(f"‚ö†Ô∏è FastSAM non trouv√©: {fastsam_path}")
                    print(f"üí° Placez FastSAM-s.pt dans {sam_models_dir} pour activer SAM")
                    return False
                
            elif self.cpu_profile.sam_model_type == 'MobileSAM' and MOBILESAM_AVAILABLE:
                # MobileSAM via mod√®le local uniquement
                mobilesam_path = sam_models_dir / 'mobile_sam.pt'
                if mobilesam_path.exists():
                    device = "cpu"  # Force CPU pour compatibilit√©
                    self.sam_model = sam_model_registry["vit_t"](checkpoint=str(mobilesam_path))
                    self.sam_model.to(device=device)
                    self.sam_predictor = SamPredictor(self.sam_model)
                    self.sam_type = 'MobileSAM'
                    print(f"‚úÖ MobileSAM charg√© depuis: {mobilesam_path}")
                else:
                    print(f"‚ö†Ô∏è MobileSAM non trouv√©: {mobilesam_path}")
                    print(f"üí° Placez mobile_sam.pt dans {sam_models_dir} pour activer SAM")
                    return False
                
            else:
                print(f"‚ùå {self.cpu_profile.sam_model_type} non disponible")
                return False
            
            load_time = (time.time() - start_time) * 1000
            print(f"‚úÖ {self.sam_type} charg√© en {load_time:.1f}ms")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur chargement SAM: {e}")
            return False
    
    def smart_detect_from_user_rectangle(self, 
                                       user_rect: Tuple[float, float, float, float],
                                       raster_patch,  # Compatible avec ou sans numpy
                                       target_class: str = None) -> SmartDetectionResult:
        """
        Pipeline principal : d√©tection intelligente √† partir du rectangle utilisateur
        
        Args:
            user_rect: Rectangle utilisateur (x1, y1, x2, y2) en pixels image
            raster_patch: Patch raster extrait de la zone d'int√©r√™t
            target_class: Classe cible recherch√©e (optionnel)
            
        Returns:
            SmartDetectionResult: R√©sultat optimis√© avec m√©tadonn√©es
        """
        start_time = time.time()
        
        print(f"üîç DEBUG SMART: smart_detect_from_user_rectangle() APPEL√âE")
        print(f"üîç DEBUG SMART: user_rect={user_rect}")
        print(f"üîç DEBUG SMART: target_class={target_class}")
        print(f"üîç DEBUG SMART: self.enabled={self.enabled}")
        print(f"üîç DEBUG SMART: self.yolo_engine pr√©sent={self.yolo_engine is not None}")
        
        if not self.enabled or not self.yolo_engine:
            # Fallback : retour bbox utilisateur sans modification
            return SmartDetectionResult(
                bbox=list(user_rect),
                bbox_original=list(user_rect),
                confidence_yolo=1.0,
                confidence_sam=None,
                class_name=target_class or "unknown",
                class_id=0,
                mask_available=False,
                mask_quality_score=None,
                refinement_applied=False,
                processing_time=(time.time() - start_time) * 1000,
                improvement_ratio=None
            )
        
        try:
            # √âtape 1: D√©tection YOLO sur le patch
            yolo_detections = self._run_yolo_detection(raster_patch, target_class)
            print(f"üîç DEBUG YOLO: Found {len(yolo_detections) if yolo_detections else 0} detections")
            if yolo_detections:
                for i, det in enumerate(yolo_detections[:3]):  # Afficher les 3 premi√®res
                    print(f"üîç DEBUG YOLO: Detection {i}: class={det.get('class_id', 'N/A')}, conf={det.get('confidence', 0):.3f}")
            
            # √âtape 2: S√©lection du meilleur candidat
            best_candidate = self._select_best_candidate(yolo_detections, user_rect, raster_patch.shape)
            print(f"üîç DEBUG SELECTION: best_candidate = {best_candidate is not None}")
            if best_candidate:
                print(f"üîç DEBUG SELECTION: Selected candidate: class={best_candidate.get('class_id', 'N/A')}, conf={best_candidate.get('confidence', 0):.3f}")
            
            if not best_candidate:
                # Aucune d√©tection ‚Üí retour rectangle utilisateur
                return self._create_fallback_result(user_rect, target_class, start_time)
            
            # √âtape 3: D√©cision raffinement SAM
            print(f"üîç DEBUG PIPELINE: Appel _should_apply_sam_refinement() avec best_candidate={best_candidate}")
            needs_sam_refinement = self._should_apply_sam_refinement(best_candidate)
            print(f"üîç DEBUG PIPELINE: needs_sam_refinement = {needs_sam_refinement}")
            
            if needs_sam_refinement:
                # √âtape 4: Raffinement SAM
                refined_result = self._apply_sam_refinement(best_candidate, raster_patch)
                if refined_result:
                    best_candidate = refined_result
            
            # √âtape 5: Construction r√©sultat final
            processing_time = (time.time() - start_time) * 1000
            
            result = SmartDetectionResult(
                bbox=best_candidate['bbox'],
                bbox_original=best_candidate.get('bbox_original', best_candidate['bbox']),
                confidence_yolo=best_candidate['confidence'],
                confidence_sam=best_candidate.get('confidence_sam'),
                class_name=best_candidate['class_name'],
                class_id=best_candidate['class_id'],
                mask_available=best_candidate.get('mask_available', False),
                mask_quality_score=best_candidate.get('mask_quality_score'),
                refinement_applied=best_candidate.get('refinement_applied', False),
                processing_time=processing_time,
                improvement_ratio=best_candidate.get('improvement_ratio'),
                
                # NOUVEAUX ATTRIBUTS POLYGONES SAM
                polygon_points=best_candidate.get('polygon_points'),
                polygon_available=best_candidate.get('polygon_available', False)
            )
            
            # Mise √† jour statistiques
            self._update_stats(result)
            
            # DEBUG LOGGING POLYGONES
            print(f"üîç DEBUG R√âSULTAT: polygon_points pr√©sent: {result.polygon_points is not None}")
            print(f"üîç DEBUG R√âSULTAT: polygon_available: {result.polygon_available}")
            if result.polygon_points:
                print(f"üîç DEBUG R√âSULTAT: nombre de vertices: {len(result.polygon_points)}")
            
            if self.debug_mode:
                print(f"üéØ Smart detection: {result.class_name} "
                      f"(YOLO: {result.confidence_yolo:.2f}, "
                      f"SAM: {result.confidence_sam or 'N/A'}, "
                      f"Temps: {result.processing_time:.1f}ms, "
                      f"Polygone: {'Oui' if result.polygon_available else 'Non'})")
            
            return result
            
        except Exception as e:
            print(f"‚ùå Erreur smart detection: {e}")
            return self._create_fallback_result(user_rect, target_class, start_time)
    
    def _run_yolo_detection(self, image_patch: np.ndarray, target_class: str = None) -> List[Dict]:
        """
        Ex√©cute d√©tection YOLO optimis√©e sur le patch
        
        Args:
            image_patch: Patch image √† analyser
            target_class: Classe cible (optionnel pour filtrage)
            
        Returns:
            List[Dict]: Liste d√©tections YOLO
        """
        try:
            # Configuration optimis√©e selon CPU - ABAISS√â POUR DEBUG
            confidence_threshold = 0.05  # Tr√®s permissif pour capturer toute d√©tection
            print(f"üîç DEBUG YOLO: confidence_threshold = {confidence_threshold} (abaiss√© pour debug)")
            print(f"üîç DEBUG YOLO: target_class = '{target_class}'")
            print(f"üîç DEBUG YOLO: image_patch shape = {image_patch.shape}")
            print(f"üîç DEBUG YOLO: image_patch dtype = {image_patch.dtype}")
            print(f"üîç DEBUG YOLO: image_patch min/max = {image_patch.min():.2f}/{image_patch.max():.2f}")
            
            # NOUVEAU: Mapping intelligent classe custom ‚Üí COCO
            from .class_mapping import get_coco_classes_for_custom_class, get_mapping_explanation
            
            coco_classes = get_coco_classes_for_custom_class(target_class)
            explanation = get_mapping_explanation(target_class)
            
            print(f"üîç DEBUG YOLO: {explanation}")
            print(f"üîç DEBUG YOLO: Classes COCO √† d√©tecter: {coco_classes}")
            print(f"üîç DEBUG YOLO: Strat√©gie: D√©tecter {coco_classes} puis reclassifier en '{target_class}'")
            
            # Debug: sauvegarder patch image pour inspection
            try:
                import cv2
                debug_path = f"C:\\temp\\debug_patch_{int(time.time())}.jpg"
                cv2.imwrite(debug_path, cv2.cvtColor(image_patch, cv2.COLOR_RGB2BGR))
                print(f"üîç DEBUG YOLO: Patch sauvegard√©: {debug_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è DEBUG YOLO: Impossible de sauver patch: {e}")
            
            # D√©tection avec seuil tr√®s permissif pour capturer tous les candidats
            detections = self.yolo_engine.detect_objects(
                image_patch,
                confidence_threshold=confidence_threshold,
                iou_threshold=0.5  # NMS standard
            )
            print(f"üîç DEBUG YOLO: Raw detections before filtering = {len(detections) if detections else 0}")
            
            # Debug: afficher TOUTES les d√©tections brutes avec classes disponibles
            if detections:
                print(f"üîç DEBUG YOLO: Classes d√©tect√©es:")
                all_classes = set()
                for i, det in enumerate(detections[:10]):  # Afficher plus de d√©tections
                    class_name = det.get('class_name', 'N/A')
                    confidence = det.get('confidence', 0)
                    print(f"üîç DEBUG YOLO: Detection {i}: '{class_name}' ({confidence:.3f})")
                    all_classes.add(class_name)
                print(f"üîç DEBUG YOLO: Classes uniques trouv√©es: {sorted(list(all_classes))}")
            else:
                print(f"üîç DEBUG YOLO: AUCUNE d√©tection trouv√©e m√™me avec seuil 5%!")
            
            # NOUVEAU: Filtrer par classes COCO mapp√©es au lieu de classe custom
            if target_class and coco_classes:
                original_count = len(detections) if detections else 0
                detections = [d for d in detections 
                            if d['class_name'] in coco_classes]
                print(f"üîç DEBUG YOLO: Filtrage COCO {coco_classes}: {len(detections)} (√©tait {original_count})")
                
                # Reclassifier les d√©tections vers la classe custom
                for det in detections:
                    det['original_coco_class'] = det['class_name']  # Sauvegarder classe COCO
                    det['class_name'] = target_class  # Reclassifier
                    print(f"üîÑ DEBUG YOLO: Reclassifi√© '{det['original_coco_class']}' ‚Üí '{target_class}'")
            
            return detections
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur d√©tection YOLO: {e}")
            return []
    
    def _select_best_candidate(self, detections: List[Dict], 
                             user_rect: Tuple[float, float, float, float],
                             image_shape: Tuple[int, int]) -> Optional[Dict]:
        """
        S√©lectionne le meilleur candidat parmi les d√©tections YOLO
        
        Crit√®res de s√©lection am√©lior√©s :
        1. Intersection maximale avec rectangle utilisateur
        2. Confiance YOLO √©lev√©e
        3. Taille coh√©rente avec s√©lection utilisateur
        4. Centrage dans la s√©lection utilisateur
        5. Coh√©rence de forme pour objets g√©ospatiaux
        
        Args:
            detections: Liste d√©tections YOLO
            user_rect: Rectangle utilisateur (x1, y1, x2, y2)
            image_shape: Dimensions image (H, W)
            
        Returns:
            Optional[Dict]: Meilleur candidat ou None
        """
        if not detections:
            return None
        
        best_candidate = None
        best_score = 0.0
        
        user_x1, user_y1, user_x2, user_y2 = user_rect
        user_center = ((user_x1 + user_x2) / 2, (user_y1 + user_y2) / 2)
        user_area = (user_x2 - user_x1) * (user_y2 - user_y1)
        
        for detection in detections:
            det_x1, det_y1, det_x2, det_y2 = detection['bbox']
            
            # Calcul intersection
            intersection_x1 = max(user_x1, det_x1)
            intersection_y1 = max(user_y1, det_y1)
            intersection_x2 = min(user_x2, det_x2)
            intersection_y2 = min(user_y2, det_y2)
            
            if intersection_x2 <= intersection_x1 or intersection_y2 <= intersection_y1:
                continue  # Pas d'intersection
            
            # M√©triques de base
            intersection_area = (intersection_x2 - intersection_x1) * (intersection_y2 - intersection_y1)
            intersection_ratio = intersection_area / user_area
            
            det_area = (det_x2 - det_x1) * (det_y2 - det_y1)
            size_similarity = min(user_area, det_area) / max(user_area, det_area)
            
            # NOUVELLES m√©triques g√©ospatiales
            centrality_score = self._calculate_centrality_score(detection, user_center)
            aspect_ratio_score = self._calculate_aspect_ratio_consistency(detection)
            
            # Score combin√© am√©lior√© avec m√©triques g√©ospatiales
            score = (
                intersection_ratio * 0.35 +     # 35% intersection avec s√©lection utilisateur
                detection['confidence'] * 0.25 + # 25% confiance YOLO
                size_similarity * 0.15 +        # 15% similarit√© de taille
                centrality_score * 0.15 +       # 15% centrage dans la s√©lection
                aspect_ratio_score * 0.10       # 10% coh√©rence forme
            )
            
            if score > best_score:
                best_score = score
                best_candidate = detection.copy()
                best_candidate['selection_score'] = score
                best_candidate['intersection_ratio'] = intersection_ratio
                best_candidate['centrality_score'] = centrality_score
                best_candidate['aspect_ratio_score'] = aspect_ratio_score
        
        return best_candidate
    
    def _calculate_centrality_score(self, detection: Dict, user_center: Tuple[float, float]) -> float:
        """Score bas√© sur le centrage de la d√©tection dans la s√©lection utilisateur"""
        det_bbox = detection['bbox']
        det_center = ((det_bbox[0] + det_bbox[2]) / 2, (det_bbox[1] + det_bbox[3]) / 2)
        
        # Distance normalis√©e du centre
        distance = ((det_center[0] - user_center[0])**2 + (det_center[1] - user_center[1])**2) ** 0.5
        
        # Plus la d√©tection est centr√©e, meilleur le score
        max_distance = 100  # Distance max acceptable en pixels
        return max(0, 1 - (distance / max_distance))
    
    def _calculate_aspect_ratio_consistency(self, detection: Dict) -> float:
        """Score bas√© sur la coh√©rence du ratio d'aspect pour objets g√©ospatiaux"""
        det_bbox = detection['bbox']
        width = det_bbox[2] - det_bbox[0]
        height = det_bbox[3] - det_bbox[1]
        
        if height == 0:
            return 0.0
        
        aspect_ratio = width / height
        
        # Ratios typiques pour objets g√©ospatiaux courants
        typical_ratios = {
            'square': 1.0,      # B√¢timents, v√©hicules vus du dessus
            'horizontal': 2.0,   # V√©hicules, infrastructures horizontales
            'vertical': 0.5      # Poteaux, arbres, objets verticaux
        }
        
        # Score bas√© sur la proximit√© aux ratios typiques
        best_score = 0.0
        for ratio_name, typical_ratio in typical_ratios.items():
            # Fonction gaussienne centr√©e sur le ratio typique
            score = math.exp(-0.5 * ((aspect_ratio - typical_ratio) / 0.5) ** 2)
            best_score = max(best_score, score)
        
        return min(1.0, best_score)
    
    def _should_apply_sam_refinement(self, detection: Dict) -> bool:
        """D√©cision intelligente sur l'utilit√© du raffinement SAM"""
        # NOUVEAU: Si contours pr√©cis activ√©s, TOUJOURS appliquer SAM
        print(f"üîç DEBUG SAM: V√©rification enable_precise_contours...")
        print(f"üîç DEBUG SAM: hasattr(self, 'enable_precise_contours') = {hasattr(self, 'enable_precise_contours')}")
        if hasattr(self, 'enable_precise_contours'):
            print(f"üîç DEBUG SAM: self.enable_precise_contours = {self.enable_precise_contours}")
        
        if hasattr(self, 'enable_precise_contours') and self.enable_precise_contours:
            print(f"üî∫ SAM FORC√â - Contours pr√©cis activ√©s")
            return True
        else:
            print(f"‚ö™ SAM non forc√© - Contours pr√©cis d√©sactiv√©s ou attribut manquant")
        
        # Logique originale pour mode automatique
        confidence = detection['confidence']
        bbox = detection['bbox']
        class_name = detection.get('class_name', 'unknown')
        
        # Crit√®res pour raffinement SAM
        conditions = [
            confidence < 0.8,  # Confiance YOLO faible
            self._is_irregular_shape_expected(class_name),  # Forme potentiellement complexe
            self._needs_precise_boundaries(class_name),  # Classe n√©cessitant pr√©cision
            self._bbox_seems_imprecise(bbox)  # Bbox semble impr√©cise
        ]
        
        should_apply = any(conditions)
        if self.debug_mode:
            print(f"üîç SAM d√©cision: {should_apply} (conf:{confidence:.2f}, classe:{class_name})")
        
        return should_apply
    
    def _is_irregular_shape_expected(self, class_name: str) -> bool:
        """D√©termine si la classe d'objet a typiquement des formes irr√©guli√®res"""
        irregular_classes = [
            'tree', 'vegetation', 'building', 'construction', 
            'damage', 'crack', 'irregular_object'
        ]
        return any(irregular in class_name.lower() for irregular in irregular_classes)
    
    def _needs_precise_boundaries(self, class_name: str) -> bool:
        """D√©termine si la classe n√©cessite des contours pr√©cis"""
        precision_classes = [
            'building', 'vehicle', 'infrastructure', 'damage',
            'construction', 'equipment'
        ]
        return any(precision in class_name.lower() for precision in precision_classes)
    
    def _bbox_seems_imprecise(self, bbox: List[float]) -> bool:
        """√âvalue si la bbox semble impr√©cise (tr√®s grande ou tr√®s petite)"""
        width = bbox[2] - bbox[0]
        height = bbox[3] - bbox[1]
        area = width * height
        
        # Bbox tr√®s petite (< 100 pixels¬≤) ou tr√®s grande (> 50000 pixels¬≤)
        return area < 100 or area > 50000
    
    def _apply_sam_refinement(self, yolo_detection: Dict, image_patch: np.ndarray) -> Optional[Dict]:
        """
        Applique raffinement SAM avec strat√©gies adaptatives
        
        Args:
            yolo_detection: D√©tection YOLO √† raffiner
            image_patch: Patch image original
            
        Returns:
            Optional[Dict]: D√©tection raffin√©e ou None si √©chec
        """
        # D√©cision intelligente sur l'utilit√© du raffinement SAM
        if not self._should_apply_sam_refinement(yolo_detection):
            return yolo_detection  # Pas de raffinement n√©cessaire
        
        if not self._lazy_load_sam_model():
            return yolo_detection  # Fallback vers YOLO
        
        try:
            x1, y1, x2, y2 = yolo_detection['bbox']
            
            if self.sam_type == 'FastSAM':
                # FastSAM : utilise bbox comme prompt
                results = self.sam_model(
                    image_patch,
                    device='cpu',
                    conf=0.4,
                    iou=0.9
                )
                
                if results and len(results) > 0 and hasattr(results[0], 'masks'):
                    masks = results[0].masks
                    if masks is not None and len(masks.data) > 0:
                        # Prendre le premier masque (plus confiant)
                        mask = masks.data[0].cpu().numpy()
                        refined_bbox = self._bbox_from_mask(mask)
                        
                        # NOUVEAU: G√©n√©ration polygone pr√©cis depuis le masque FastSAM (si activ√©)
                        polygon_points = None
                        contour_area = None
                        if self.enable_precise_contours:
                            polygon_points, contour_area = self._polygon_from_mask_with_area(
                                mask,
                                simplification_tolerance=2.0,  # Configuration par d√©faut
                                min_area_pixels=50
                            )
                        
                        if refined_bbox:
                            refined_detection = yolo_detection.copy()
                            refined_detection['bbox'] = refined_bbox
                            refined_detection['bbox_original'] = yolo_detection['bbox']
                            refined_detection['confidence_sam'] = 0.8  # Score par d√©faut FastSAM
                            refined_detection['mask_available'] = True
                            refined_detection['mask_quality_score'] = self._calculate_mask_quality(mask)
                            refined_detection['refinement_applied'] = True
                            refined_detection['improvement_ratio'] = self._calculate_improvement_ratio(
                                yolo_detection['bbox'], refined_bbox
                            )
                            
                            # NOUVEAU: Ajout des donn√©es de polygone pr√©cis FastSAM
                            if polygon_points:
                                refined_detection['polygon_points'] = polygon_points
                                refined_detection['polygon_available'] = True
                                refined_detection['vertex_count'] = len(polygon_points) - 1  # -1 car point ferm√© dupliqu√©
                                refined_detection['area_pixels'] = contour_area
                                print(f"üî∫ Contour pr√©cis FastSAM g√©n√©r√©: {len(polygon_points)-1} vertices, aire: {contour_area:.1f}px¬≤")
                            else:
                                refined_detection['polygon_available'] = False
                                print("‚ö†Ô∏è √âchec g√©n√©ration polygone FastSAM, utilisation bbox uniquement")
                            
                            return refined_detection
            
            elif self.sam_type == 'MobileSAM':
                # MobileSAM : utilise bbox comme prompt box
                self.sam_predictor.set_image(image_patch)
                
                # Prompt box format: [x1, y1, x2, y2]
                input_box = np.array([x1, y1, x2, y2])
                
                masks, scores, _ = self.sam_predictor.predict(
                    point_coords=None,
                    point_labels=None,
                    box=input_box[None, :],
                    multimask_output=False
                )
                
                if len(masks) > 0 and len(scores) > 0:
                    mask = masks[0]
                    confidence_sam = float(scores[0])
                    
                    refined_bbox = self._bbox_from_mask(mask)
                    
                    # NOUVEAU: G√©n√©ration polygone pr√©cis depuis le masque SAM (si activ√©)
                    polygon_points = None
                    contour_area = None
                    if self.enable_precise_contours:
                        polygon_points, contour_area = self._polygon_from_mask_with_area(
                            mask,
                            simplification_tolerance=2.0,  # Configuration par d√©faut
                            min_area_pixels=50
                        )
                    
                    if refined_bbox:
                        refined_detection = yolo_detection.copy()
                        refined_detection['bbox'] = refined_bbox
                        refined_detection['bbox_original'] = yolo_detection['bbox']
                        refined_detection['confidence_sam'] = confidence_sam
                        refined_detection['mask_available'] = True
                        refined_detection['mask_quality_score'] = self._calculate_mask_quality(mask)
                        refined_detection['refinement_applied'] = True
                        refined_detection['improvement_ratio'] = self._calculate_improvement_ratio(
                            yolo_detection['bbox'], refined_bbox
                        )
                        
                        # NOUVEAU: Ajout des donn√©es de polygone pr√©cis
                        if polygon_points:
                            refined_detection['polygon_points'] = polygon_points
                            refined_detection['polygon_available'] = True
                            refined_detection['vertex_count'] = len(polygon_points) - 1  # -1 car point ferm√© dupliqu√©
                            refined_detection['area_pixels'] = contour_area
                            print(f"üî∫ Contour pr√©cis g√©n√©r√©: {len(polygon_points)-1} vertices, aire: {contour_area:.1f}px¬≤")
                        else:
                            refined_detection['polygon_available'] = False
                            print("‚ö†Ô∏è √âchec g√©n√©ration polygone, utilisation bbox uniquement")
                        
                        return refined_detection
            
            return None
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur raffinement SAM: {e}")
            return None
    
    def _bbox_from_mask(self, mask: np.ndarray) -> Optional[List[float]]:
        """
        Calcule bbox optimale √† partir d'un masque SAM
        
        Args:
            mask: Masque binaire SAM
            
        Returns:
            Optional[List[float]]: [x1, y1, x2, y2] ou None
        """
        try:
            # Trouver contours du masque
            mask_uint8 = (mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return None
            
            # Prendre le plus grand contour
            largest_contour = max(contours, key=cv2.contourArea)
            
            # Calculer bounding box
            x, y, w, h = cv2.boundingRect(largest_contour)
            
            return [float(x), float(y), float(x + w), float(y + h)]
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur calcul bbox depuis masque: {e}")
            return None
    
    def _polygon_from_mask(self, mask: np.ndarray, simplification_tolerance: float = 2.0, 
                          min_area_pixels: int = 100) -> Optional[List[List[float]]]:
        """
        Convertit un masque SAM en polygone pr√©cis avec contours simplifi√©s
        
        Args:
            mask: Masque binaire SAM (numpy array)
            simplification_tolerance: Tol√©rance simplification contour (pixels)
            min_area_pixels: Aire minimale pour polygone valide
            
        Returns:
            Optional[List[List[float]]]: Liste de points [x, y] du polygone ou None si √©chec
        """
        try:
            # Conversion masque en uint8 pour OpenCV
            mask_uint8 = (mask * 255).astype(np.uint8)
            
            # Extraction contours - m√™me m√©thode que _bbox_from_mask()
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return None
                
            # S√©lection du plus grand contour (m√™me logique que bbox)
            largest_contour = max(contours, key=cv2.contourArea)
            
            # Validation aire minimale
            if cv2.contourArea(largest_contour) < min_area_pixels:
                return None
                
            # Simplification contour avec approximation polygonale
            epsilon = simplification_tolerance
            simplified_contour = cv2.approxPolyDP(largest_contour, epsilon, True)
            
            # Validation vertices minimums
            if len(simplified_contour) < 3:
                return None
                
            # Conversion en liste de points [x, y]
            polygon_points = []
            for point in simplified_contour:
                x, y = point[0]  # OpenCV format: point[0] = [x, y]
                polygon_points.append([float(x), float(y)])
                
            # Fermeture automatique du polygone si n√©cessaire
            if polygon_points[0] != polygon_points[-1]:
                polygon_points.append(polygon_points[0])
                
            print(f"üî∫ Polygone g√©n√©r√©: {len(polygon_points)} vertices, aire: {cv2.contourArea(largest_contour):.1f}px¬≤")
            return polygon_points
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur g√©n√©ration polygone: {e}")
            return None
    
    def _polygon_from_mask_with_area(self, mask: np.ndarray, simplification_tolerance: float = 2.0, 
                                    min_area_pixels: int = 100) -> Tuple[Optional[List[List[float]]], Optional[float]]:
        """
        Version √©tendue qui retourne aussi l'aire du contour
        
        Returns:
            Tuple[polygon_points, contour_area]: Points du polygone et aire en pixels
        """
        try:
            mask_uint8 = (mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return None, None
                
            largest_contour = max(contours, key=cv2.contourArea)
            contour_area = cv2.contourArea(largest_contour)
            
            if contour_area < min_area_pixels:
                return None, None
                
            epsilon = simplification_tolerance
            simplified_contour = cv2.approxPolyDP(largest_contour, epsilon, True)
            
            if len(simplified_contour) < 3:
                return None, None
                
            polygon_points = []
            for point in simplified_contour:
                x, y = point[0]
                polygon_points.append([float(x), float(y)])
                
            if polygon_points[0] != polygon_points[-1]:
                polygon_points.append(polygon_points[0])
                
            print(f"üî∫ Polygone g√©n√©r√©: {len(polygon_points)} vertices, aire: {contour_area:.1f}px¬≤")
            return polygon_points, contour_area
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur g√©n√©ration polygone: {e}")
            return None, None
    
    def _calculate_mask_quality(self, mask: np.ndarray) -> float:
        """
        Calcule score de qualit√© d'un masque SAM
        
        Args:
            mask: Masque binaire
            
        Returns:
            float: Score qualit√© 0-1
        """
        try:
            # M√©triques de qualit√© basiques
            total_pixels = mask.size
            object_pixels = np.sum(mask > 0.5)
            
            if object_pixels == 0:
                return 0.0
            
            # Ratio objet/arri√®re-plan (id√©al ~0.1-0.3 pour objets typiques)
            object_ratio = object_pixels / total_pixels
            
            # Compacit√© (p√©rim√®tre¬≤ / aire) - plus bas = plus compact
            mask_uint8 = (mask * 255).astype(np.uint8)
            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                area = cv2.contourArea(largest_contour)
                perimeter = cv2.arcLength(largest_contour, True)
                
                if area > 0 and perimeter > 0:
                    compactness = (perimeter * perimeter) / (4 * np.pi * area)
                    compactness_score = 1.0 / (1.0 + compactness)  # Normalis√©
                else:
                    compactness_score = 0.5
            else:
                compactness_score = 0.5
            
            # Score combin√©
            quality_score = (
                min(object_ratio * 4, 1.0) * 0.4 +  # Ratio objet (cap √† 0.25)
                compactness_score * 0.6               # Compacit√©
            )
            
            return max(0.0, min(1.0, quality_score))
            
        except Exception:
            return 0.5  # Score neutre en cas d'erreur
    
    def _calculate_improvement_ratio(self, bbox_original: List[float], bbox_refined: List[float]) -> float:
        """
        Calcule le ratio d'am√©lioration entre bbox originale et raffin√©e
        
        Args:
            bbox_original: Bbox YOLO [x1, y1, x2, y2]
            bbox_refined: Bbox SAM [x1, y1, x2, y2]
            
        Returns:
            float: Ratio am√©lioration (>1 = am√©lioration, <1 = d√©gradation)
        """
        try:
            # Calcul aires
            def bbox_area(bbox):
                return (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])
            
            area_original = bbox_area(bbox_original)
            area_refined = bbox_area(bbox_refined)
            
            if area_original <= 0:
                return 1.0
            
            # Ratio de changement d'aire (mesure indirecte de pr√©cision)
            area_ratio = area_refined / area_original
            
            # Hypoth√®se : SAM est g√©n√©ralement plus pr√©cis, donc aire plus petite = meilleur
            if area_ratio < 1.0:
                return 1.0 / area_ratio  # Am√©lioration
            else:
                return area_ratio  # Possible d√©gradation
                
        except Exception:
            return 1.0  # Neutre en cas d'erreur
    
    def _create_fallback_result(self, user_rect: Tuple[float, float, float, float], 
                              target_class: str, start_time: float) -> SmartDetectionResult:
        """
        Cr√©e r√©sultat fallback en cas d'√©chec d√©tection intelligente
        
        Args:
            user_rect: Rectangle utilisateur original
            target_class: Classe cible
            start_time: Timestamp d√©but traitement
            
        Returns:
            SmartDetectionResult: R√©sultat fallback
        """
        return SmartDetectionResult(
            bbox=list(user_rect),
            bbox_original=list(user_rect),
            confidence_yolo=0.5,  # Confiance neutre
            confidence_sam=None,
            class_name=target_class or "unknown",
            class_id=0,
            mask_available=False,
            mask_quality_score=None,
            refinement_applied=False,
            processing_time=(time.time() - start_time) * 1000,
            improvement_ratio=None
        )
    
    def _update_stats(self, result: SmartDetectionResult):
        """Met √† jour les statistiques de d√©tection"""
        with self._processing_lock:
            self.detection_stats['total_detections'] += 1
            
            if result.refinement_applied:
                self.detection_stats['sam_refinements'] += 1
            
            if result.confidence_yolo > 0.8:
                self.detection_stats['auto_accepted'] += 1
            else:
                self.detection_stats['user_validated'] += 1
            
            # Moyenne mobile du temps de traitement
            n = self.detection_stats['total_detections']
            current_avg = self.detection_stats['avg_processing_time']
            new_avg = ((current_avg * (n - 1)) + result.processing_time) / n
            self.detection_stats['avg_processing_time'] = new_avg
    
    def get_performance_stats(self) -> Dict:
        """
        Retourne les statistiques de performance du moteur
        
        Returns:
            Dict: Statistiques d√©taill√©es
        """
        with self._processing_lock:
            total = self.detection_stats['total_detections']
            return {
                'cpu_profile': self.cpu_profile.level,
                'total_detections': total,
                'sam_usage_rate': (self.detection_stats['sam_refinements'] / total * 100) if total > 0 else 0,
                'auto_acceptance_rate': (self.detection_stats['auto_accepted'] / total * 100) if total > 0 else 0,
                'avg_processing_time_ms': self.detection_stats['avg_processing_time'],
                'enabled': self.enabled,
                'sam_available': self.sam_model is not None
            }
    
    def enable_debug_mode(self, enabled: bool = True):
        """Active/d√©sactive le mode debug avec logs d√©taill√©s"""
        self.debug_mode = enabled
        print(f"üêõ Mode debug: {'Activ√©' if enabled else 'D√©sactiv√©'}")
    
    def cleanup(self):
        """Nettoie les ressources (mod√®les, cache)"""
        try:
            if self.sam_model is not None:
                del self.sam_model
                self.sam_model = None
            
            if self.sam_predictor is not None:
                del self.sam_predictor
                self.sam_predictor = None
            
            # Force garbage collection
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            print("‚úÖ SmartAnnotationEngine nettoy√©")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur nettoyage SmartAnnotationEngine: {e}")